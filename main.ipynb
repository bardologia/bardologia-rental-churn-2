{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d85a1591",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "from datetime import datetime\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "sys.path.append(os.path.abspath(os.path.join(current_dir, '..')))\n",
    "\n",
    "from Model.core import run_pipeline\n",
    "from Model.data import DataModule\n",
    "from Model.network import Model\n",
    "from Model.trainer import Trainer\n",
    "from Configs.config import config\n",
    "from Utils.logger import Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3c3f2c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_root = current_dir  \n",
    "\n",
    "run_id = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "run_dir = os.path.join(project_root, \"runs\", run_id)\n",
    "checkpoint_dir = os.path.join(run_dir, \"checkpoints\")\n",
    "\n",
    "model_save_path = os.path.join(checkpoint_dir, \"best_model.pth\")\n",
    "log_dir = run_dir \n",
    "\n",
    "raw_path = os.path.join(project_root, config.paths.raw_data)\n",
    "data_path = os.path.join(project_root, config.paths.train_data)\n",
    "\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(os.path.dirname(data_path), exist_ok=True)\n",
    "    run_pipeline(raw_path, data_path)\n",
    "    print(f\"Generated new training data: {data_path}\")\n",
    "\n",
    "logger = Logger(log_dir=log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "623e5f54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TensorBoard on c:\\Users\\Victo\\OneDrive\\Área de Trabalho\\Project-2\\project - 2\\runs...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6014 (pid 9000), started 14:58:42 ago. (Use '!kill 9000' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-9f1d6be9d6e48561\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-9f1d6be9d6e48561\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6014;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "runs_dir = os.path.join(project_root, \"runs\")\n",
    "\n",
    "print(f\"Starting TensorBoard on {runs_dir}...\")\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir \"{runs_dir}\" --port 6014 --reload_interval 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33d195e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-15 11:21:50,919 - logger - INFO - Loading data from c:\\Users\\Victo\\OneDrive\\Área de Trabalho\\Project-2\\project - 2\\Data/training_data.csv\n",
      "2026-01-15 11:21:51,309 - logger - INFO - Categorical Features: 9\n",
      "2026-01-15 11:21:51,309 - logger - INFO - Continuous Features: 17\n",
      "2026-01-15 11:21:51,523 - logger - INFO - Random Split Strategy Implemented (seed=42)\n",
      "2026-01-15 11:21:51,527 - logger - INFO - Class imbalance ratio (neg:pos): 24.8:1\n",
      "2026-01-15 11:21:51,551 - logger - INFO - Using balanced sampling with target ratio: 20.0%\n",
      "2026-01-15 11:21:51,551 - logger - INFO - Train Size: 55119\n",
      "2026-01-15 11:21:51,553 - logger - INFO - Val Size: 11812\n",
      "2026-01-15 11:21:51,553 - logger - INFO - Test Size: 11812\n",
      "2026-01-15 11:21:51,556 - logger - INFO - Class Distribution - Train: 3.88% pos, Val: 3.97% pos, Test: 4.10% pos\n",
      "2026-01-15 11:21:51,582 - logger - INFO - Parameters: 124,586\n",
      "2026-01-15 11:21:51,706 - logger - INFO - Using Asymmetric Loss (gamma_neg=4, gamma_pos=0, pos_weight=15)\n",
      "2026-01-15 11:21:53,444 - logger - INFO - Training on device: cuda\n",
      "Train Epoch 0: 100%|██████████| 216/216 [00:06<00:00, 31.06it/s, loss=0.352, lr=0.0005]\n",
      "Val Epoch 0: 100%|██████████| 47/47 [00:00<00:00, 81.43it/s, loss=0.293]\n",
      "2026-01-15 11:22:01,713 - logger - INFO - New best model saved to c:\\Users\\Victo\\OneDrive\\Área de Trabalho\\Project-2\\project - 2\\runs\\20260115_112150\\checkpoints\\best_model.pth with AUC: 0.1225\n",
      "2026-01-15 11:22:01,713 - logger - INFO - Epoch 1/150 | Train Loss: 0.8462 | Val Loss: 0.4474 | AUC: 0.1225 | LR: 5.00e-04 *\n",
      "Train Epoch 1: 100%|██████████| 216/216 [00:06<00:00, 33.78it/s, loss=0.508, lr=0.0005]\n",
      "Val Epoch 1: 100%|██████████| 47/47 [00:00<00:00, 78.64it/s, loss=0.284]\n",
      "2026-01-15 11:22:09,444 - logger - INFO - New best model saved to c:\\Users\\Victo\\OneDrive\\Área de Trabalho\\Project-2\\project - 2\\runs\\20260115_112150\\checkpoints\\best_model.pth with AUC: 0.1230\n",
      "2026-01-15 11:22:09,444 - logger - INFO - Epoch 2/150 | Train Loss: 0.7649 | Val Loss: 0.4597 | AUC: 0.1230 | LR: 5.00e-04 *\n",
      "Train Epoch 2: 100%|██████████| 216/216 [00:06<00:00, 33.80it/s, loss=0.58, lr=0.0005] \n",
      "Val Epoch 2: 100%|██████████| 47/47 [00:00<00:00, 85.73it/s, loss=0.272]\n",
      "2026-01-15 11:22:17,049 - logger - INFO - New best model saved to c:\\Users\\Victo\\OneDrive\\Área de Trabalho\\Project-2\\project - 2\\runs\\20260115_112150\\checkpoints\\best_model.pth with AUC: 0.1301\n",
      "2026-01-15 11:22:17,050 - logger - INFO - Epoch 3/150 | Train Loss: 0.7738 | Val Loss: 0.4469 | AUC: 0.1301 | LR: 5.00e-04 *\n",
      "Train Epoch 3: 100%|██████████| 216/216 [00:06<00:00, 33.25it/s, loss=0.717, lr=0.0005]\n",
      "Val Epoch 3: 100%|██████████| 47/47 [00:00<00:00, 83.88it/s, loss=0.284]\n",
      "2026-01-15 11:22:24,736 - logger - INFO - Epoch 4/150 | Train Loss: 0.7576 | Val Loss: 0.4499 | AUC: 0.1221 | LR: 5.00e-04 \n",
      "Train Epoch 4: 100%|██████████| 216/216 [00:06<00:00, 33.51it/s, loss=0.518, lr=0.0005]\n",
      "Val Epoch 4: 100%|██████████| 47/47 [00:00<00:00, 75.97it/s, loss=0.273]\n",
      "2026-01-15 11:22:32,427 - logger - INFO - Epoch 5/150 | Train Loss: 0.7433 | Val Loss: 0.4558 | AUC: 0.1225 | LR: 5.00e-04 \n",
      "Train Epoch 5: 100%|██████████| 216/216 [00:06<00:00, 33.22it/s, loss=0.517, lr=0.0005]\n",
      "Val Epoch 5: 100%|██████████| 47/47 [00:00<00:00, 76.10it/s, loss=0.321]\n",
      "2026-01-15 11:22:40,192 - logger - INFO - Epoch 6/150 | Train Loss: 0.7445 | Val Loss: 0.5093 | AUC: 0.1219 | LR: 5.00e-04 \n",
      "Train Epoch 6: 100%|██████████| 216/216 [00:06<00:00, 33.25it/s, loss=0.564, lr=0.0005]\n",
      "Val Epoch 6: 100%|██████████| 47/47 [00:00<00:00, 70.87it/s, loss=0.276]\n",
      "2026-01-15 11:22:48,025 - logger - INFO - Epoch 7/150 | Train Loss: 0.7418 | Val Loss: 0.4649 | AUC: 0.1207 | LR: 5.00e-04 \n",
      "Train Epoch 7: 100%|██████████| 216/216 [00:06<00:00, 33.16it/s, loss=0.911, lr=0.0005]\n",
      "Val Epoch 7: 100%|██████████| 47/47 [00:00<00:00, 85.95it/s, loss=0.313]\n",
      "2026-01-15 11:22:55,751 - logger - INFO - Epoch 8/150 | Train Loss: 0.7356 | Val Loss: 0.4943 | AUC: 0.1213 | LR: 5.00e-04 \n",
      "Train Epoch 8: 100%|██████████| 216/216 [00:06<00:00, 32.57it/s, loss=0.622, lr=0.0005]\n",
      "Val Epoch 8: 100%|██████████| 47/47 [00:00<00:00, 74.32it/s, loss=0.266]\n",
      "2026-01-15 11:23:03,685 - logger - INFO - Epoch 9/150 | Train Loss: 0.7313 | Val Loss: 0.4563 | AUC: 0.1195 | LR: 5.00e-04 \n",
      "Train Epoch 9: 100%|██████████| 216/216 [00:06<00:00, 32.25it/s, loss=0.641, lr=0.0005]\n",
      "Val Epoch 9: 100%|██████████| 47/47 [00:00<00:00, 85.52it/s, loss=0.313]\n",
      "2026-01-15 11:23:11,592 - logger - INFO - Epoch 10/150 | Train Loss: 0.7243 | Val Loss: 0.4901 | AUC: 0.1197 | LR: 5.00e-04 \n",
      "Train Epoch 10: 100%|██████████| 216/216 [00:06<00:00, 32.87it/s, loss=0.612, lr=0.0005]\n",
      "Val Epoch 10: 100%|██████████| 47/47 [00:00<00:00, 74.66it/s, loss=0.282]\n",
      "2026-01-15 11:23:19,441 - logger - INFO - Epoch 11/150 | Train Loss: 0.7246 | Val Loss: 0.4797 | AUC: 0.1236 | LR: 5.00e-04 \n",
      "Train Epoch 11: 100%|██████████| 216/216 [00:06<00:00, 33.30it/s, loss=0.688, lr=0.0005]\n",
      "Val Epoch 11: 100%|██████████| 47/47 [00:00<00:00, 82.33it/s, loss=0.298]\n",
      "2026-01-15 11:23:27,128 - logger - INFO - LR reduced: 5.00e-04 -> 2.50e-04\n",
      "2026-01-15 11:23:27,162 - logger - INFO - Epoch 12/150 | Train Loss: 0.7253 | Val Loss: 0.4880 | AUC: 0.1221 | LR: 2.50e-04 \n",
      "Train Epoch 12: 100%|██████████| 216/216 [00:06<00:00, 31.94it/s, loss=0.91, lr=0.00025] \n",
      "Val Epoch 12: 100%|██████████| 47/47 [00:00<00:00, 56.74it/s, loss=0.336]\n",
      "2026-01-15 11:23:35,642 - logger - INFO - Epoch 13/150 | Train Loss: 0.7179 | Val Loss: 0.5110 | AUC: 0.1249 | LR: 2.50e-04 \n",
      "Train Epoch 13: 100%|██████████| 216/216 [00:08<00:00, 26.37it/s, loss=0.669, lr=0.00025]\n",
      "Val Epoch 13: 100%|██████████| 47/47 [00:00<00:00, 85.28it/s, loss=0.299]\n",
      "2026-01-15 11:23:45,073 - logger - INFO - Epoch 14/150 | Train Loss: 0.7081 | Val Loss: 0.4981 | AUC: 0.1274 | LR: 2.50e-04 \n",
      "Train Epoch 14: 100%|██████████| 216/216 [00:06<00:00, 32.66it/s, loss=0.555, lr=0.00025]\n",
      "Val Epoch 14: 100%|██████████| 47/47 [00:00<00:00, 71.53it/s, loss=0.282]\n",
      "2026-01-15 11:23:53,055 - logger - INFO - Epoch 15/150 | Train Loss: 0.7100 | Val Loss: 0.5182 | AUC: 0.1271 | LR: 2.50e-04 \n",
      "Train Epoch 15: 100%|██████████| 216/216 [00:06<00:00, 31.27it/s, loss=0.697, lr=0.00025]\n",
      "Val Epoch 15: 100%|██████████| 47/47 [00:00<00:00, 73.86it/s, loss=0.28] \n",
      "2026-01-15 11:24:01,333 - logger - INFO - Epoch 16/150 | Train Loss: 0.7061 | Val Loss: 0.5025 | AUC: 0.1278 | LR: 2.50e-04 \n",
      "Train Epoch 16: 100%|██████████| 216/216 [00:08<00:00, 25.94it/s, loss=0.535, lr=0.00025]\n",
      "Val Epoch 16: 100%|██████████| 47/47 [00:00<00:00, 67.64it/s, loss=0.282]\n",
      "2026-01-15 11:24:11,144 - logger - INFO - Epoch 17/150 | Train Loss: 0.7029 | Val Loss: 0.5086 | AUC: 0.1212 | LR: 2.50e-04 \n",
      "Train Epoch 17: 100%|██████████| 216/216 [00:08<00:00, 26.56it/s, loss=0.556, lr=0.00025]\n",
      "Val Epoch 17: 100%|██████████| 47/47 [00:00<00:00, 69.82it/s, loss=0.3]  \n",
      "2026-01-15 11:24:20,704 - logger - INFO - Epoch 18/150 | Train Loss: 0.6980 | Val Loss: 0.5263 | AUC: 0.1291 | LR: 2.50e-04 \n",
      "Train Epoch 18: 100%|██████████| 216/216 [00:08<00:00, 24.36it/s, loss=0.766, lr=0.00025]\n",
      "Val Epoch 18: 100%|██████████| 47/47 [00:00<00:00, 73.11it/s, loss=0.276]\n",
      "2026-01-15 11:24:30,981 - logger - INFO - Epoch 19/150 | Train Loss: 0.7040 | Val Loss: 0.4974 | AUC: 0.1259 | LR: 2.50e-04 \n",
      "Train Epoch 19: 100%|██████████| 216/216 [00:07<00:00, 30.27it/s, loss=0.546, lr=0.00025]\n",
      "Val Epoch 19: 100%|██████████| 47/47 [00:00<00:00, 69.63it/s, loss=0.268]\n",
      "2026-01-15 11:24:39,577 - logger - INFO - New best model saved to c:\\Users\\Victo\\OneDrive\\Área de Trabalho\\Project-2\\project - 2\\runs\\20260115_112150\\checkpoints\\best_model.pth with AUC: 0.1324\n",
      "2026-01-15 11:24:39,579 - logger - INFO - Epoch 20/150 | Train Loss: 0.6976 | Val Loss: 0.5285 | AUC: 0.1324 | LR: 2.50e-04 *\n",
      "Train Epoch 20: 100%|██████████| 216/216 [00:06<00:00, 31.56it/s, loss=0.713, lr=0.00025]\n",
      "Val Epoch 20: 100%|██████████| 47/47 [00:00<00:00, 81.04it/s, loss=0.311]\n",
      "2026-01-15 11:24:47,689 - logger - INFO - Epoch 21/150 | Train Loss: 0.7001 | Val Loss: 0.5212 | AUC: 0.1268 | LR: 2.50e-04 \n",
      "Train Epoch 21: 100%|██████████| 216/216 [00:07<00:00, 28.12it/s, loss=0.733, lr=0.00025]\n",
      "Val Epoch 21: 100%|██████████| 47/47 [00:01<00:00, 36.57it/s, loss=0.284]\n",
      "2026-01-15 11:24:58,257 - logger - INFO - Epoch 22/150 | Train Loss: 0.6993 | Val Loss: 0.5347 | AUC: 0.1291 | LR: 2.50e-04 \n",
      "Train Epoch 22: 100%|██████████| 216/216 [00:07<00:00, 27.34it/s, loss=0.691, lr=0.00025]\n",
      "Val Epoch 22: 100%|██████████| 47/47 [00:01<00:00, 41.05it/s, loss=0.287]\n",
      "2026-01-15 11:25:08,229 - logger - INFO - Epoch 23/150 | Train Loss: 0.6840 | Val Loss: 0.5392 | AUC: 0.1235 | LR: 2.50e-04 \n",
      "Train Epoch 23: 100%|██████████| 216/216 [00:07<00:00, 27.22it/s, loss=0.975, lr=0.00025]\n",
      "Val Epoch 23: 100%|██████████| 47/47 [00:00<00:00, 64.09it/s, loss=0.286]\n",
      "2026-01-15 11:25:17,784 - logger - INFO - Epoch 24/150 | Train Loss: 0.6893 | Val Loss: 0.5492 | AUC: 0.1200 | LR: 2.50e-04 \n",
      "Train Epoch 24: 100%|██████████| 216/216 [00:07<00:00, 27.24it/s, loss=0.773, lr=0.00025]\n",
      "Val Epoch 24: 100%|██████████| 47/47 [00:00<00:00, 79.77it/s, loss=0.322]\n",
      "2026-01-15 11:25:27,081 - logger - INFO - Epoch 25/150 | Train Loss: 0.6770 | Val Loss: 0.5347 | AUC: 0.1243 | LR: 2.50e-04 \n",
      "Train Epoch 25: 100%|██████████| 216/216 [00:08<00:00, 25.76it/s, loss=0.621, lr=0.00025]\n",
      "Val Epoch 25: 100%|██████████| 47/47 [00:01<00:00, 44.26it/s, loss=0.281]\n",
      "2026-01-15 11:25:37,847 - logger - INFO - Epoch 26/150 | Train Loss: 0.6850 | Val Loss: 0.5484 | AUC: 0.1222 | LR: 2.50e-04 \n",
      "Train Epoch 26: 100%|██████████| 216/216 [00:07<00:00, 29.60it/s, loss=0.823, lr=0.00025]\n",
      "Val Epoch 26: 100%|██████████| 47/47 [00:00<00:00, 63.39it/s, loss=0.336]\n",
      "2026-01-15 11:25:46,886 - logger - INFO - Epoch 27/150 | Train Loss: 0.6841 | Val Loss: 0.5767 | AUC: 0.1243 | LR: 2.50e-04 \n",
      "Train Epoch 27: 100%|██████████| 216/216 [00:07<00:00, 27.70it/s, loss=0.704, lr=0.00025]\n",
      "Val Epoch 27: 100%|██████████| 47/47 [00:00<00:00, 72.00it/s, loss=0.314]\n",
      "2026-01-15 11:25:56,131 - logger - INFO - Epoch 28/150 | Train Loss: 0.6765 | Val Loss: 0.5633 | AUC: 0.1176 | LR: 2.50e-04 \n",
      "Train Epoch 28: 100%|██████████| 216/216 [00:08<00:00, 25.43it/s, loss=1.05, lr=0.00025] \n",
      "Val Epoch 28: 100%|██████████| 47/47 [00:00<00:00, 75.82it/s, loss=0.321]\n",
      "2026-01-15 11:26:06,041 - logger - INFO - LR reduced: 2.50e-04 -> 1.25e-04\n",
      "2026-01-15 11:26:06,089 - logger - INFO - Epoch 29/150 | Train Loss: 0.6780 | Val Loss: 0.5532 | AUC: 0.1189 | LR: 1.25e-04 \n",
      "Train Epoch 29: 100%|██████████| 216/216 [00:07<00:00, 28.97it/s, loss=0.718, lr=0.000125]\n",
      "Val Epoch 29: 100%|██████████| 47/47 [00:00<00:00, 61.32it/s, loss=0.329]\n",
      "2026-01-15 11:26:15,083 - logger - INFO - Epoch 30/150 | Train Loss: 0.6627 | Val Loss: 0.5860 | AUC: 0.1263 | LR: 1.25e-04 \n",
      "Train Epoch 30: 100%|██████████| 216/216 [00:09<00:00, 22.66it/s, loss=0.653, lr=0.000125]\n",
      "Val Epoch 30: 100%|██████████| 47/47 [00:00<00:00, 62.24it/s, loss=0.341]\n",
      "2026-01-15 11:26:26,180 - logger - INFO - Epoch 31/150 | Train Loss: 0.6817 | Val Loss: 0.5655 | AUC: 0.1207 | LR: 1.25e-04 \n",
      "Train Epoch 31: 100%|██████████| 216/216 [00:08<00:00, 24.49it/s, loss=0.63, lr=0.000125] \n",
      "Val Epoch 31: 100%|██████████| 47/47 [00:00<00:00, 57.31it/s, loss=0.282]\n",
      "2026-01-15 11:26:36,796 - logger - INFO - Epoch 32/150 | Train Loss: 0.6727 | Val Loss: 0.5627 | AUC: 0.1223 | LR: 1.25e-04 \n",
      "Train Epoch 32: 100%|██████████| 216/216 [00:11<00:00, 18.51it/s, loss=0.836, lr=0.000125]\n",
      "Val Epoch 32: 100%|██████████| 47/47 [00:00<00:00, 56.84it/s, loss=0.301]\n",
      "2026-01-15 11:26:50,166 - logger - INFO - Epoch 33/150 | Train Loss: 0.6724 | Val Loss: 0.5900 | AUC: 0.1192 | LR: 1.25e-04 \n",
      "Train Epoch 33: 100%|██████████| 216/216 [00:07<00:00, 30.30it/s, loss=0.445, lr=0.000125]\n",
      "Val Epoch 33: 100%|██████████| 47/47 [00:00<00:00, 76.72it/s, loss=0.298]\n",
      "2026-01-15 11:26:58,601 - logger - INFO - Epoch 34/150 | Train Loss: 0.6612 | Val Loss: 0.5862 | AUC: 0.1187 | LR: 1.25e-04 \n",
      "Train Epoch 34: 100%|██████████| 216/216 [00:06<00:00, 31.25it/s, loss=0.516, lr=0.000125]\n",
      "Val Epoch 34: 100%|██████████| 47/47 [00:00<00:00, 73.97it/s, loss=0.323]\n",
      "2026-01-15 11:27:06,807 - logger - INFO - Epoch 35/150 | Train Loss: 0.6756 | Val Loss: 0.5943 | AUC: 0.1188 | LR: 1.25e-04 \n",
      "Train Epoch 35: 100%|██████████| 216/216 [00:06<00:00, 32.13it/s, loss=0.697, lr=0.000125]\n",
      "Val Epoch 35: 100%|██████████| 47/47 [00:00<00:00, 82.62it/s, loss=0.326]\n",
      "2026-01-15 11:27:14,802 - logger - INFO - Epoch 36/150 | Train Loss: 0.6646 | Val Loss: 0.6023 | AUC: 0.1201 | LR: 1.25e-04 \n",
      "Train Epoch 36: 100%|██████████| 216/216 [00:06<00:00, 32.09it/s, loss=0.434, lr=0.000125]\n",
      "Val Epoch 36: 100%|██████████| 47/47 [00:00<00:00, 80.49it/s, loss=0.271]\n",
      "2026-01-15 11:27:22,856 - logger - INFO - Epoch 37/150 | Train Loss: 0.6587 | Val Loss: 0.6023 | AUC: 0.1213 | LR: 1.25e-04 \n",
      "Train Epoch 37: 100%|██████████| 216/216 [00:06<00:00, 32.41it/s, loss=0.472, lr=0.000125]\n",
      "Val Epoch 37: 100%|██████████| 47/47 [00:00<00:00, 77.86it/s, loss=0.335]\n",
      "2026-01-15 11:27:30,793 - logger - INFO - LR reduced: 1.25e-04 -> 6.25e-05\n",
      "2026-01-15 11:27:30,837 - logger - INFO - Epoch 38/150 | Train Loss: 0.6705 | Val Loss: 0.6201 | AUC: 0.1194 | LR: 6.25e-05 \n",
      "Train Epoch 38: 100%|██████████| 216/216 [00:06<00:00, 32.28it/s, loss=0.464, lr=6.25e-5]\n",
      "Val Epoch 38: 100%|██████████| 47/47 [00:00<00:00, 70.09it/s, loss=0.324]\n",
      "2026-01-15 11:27:38,892 - logger - INFO - Epoch 39/150 | Train Loss: 0.6604 | Val Loss: 0.6140 | AUC: 0.1159 | LR: 6.25e-05 \n",
      "Train Epoch 39: 100%|██████████| 216/216 [00:06<00:00, 31.55it/s, loss=0.669, lr=6.25e-5]\n",
      "Val Epoch 39: 100%|██████████| 47/47 [00:00<00:00, 71.79it/s, loss=0.295]\n",
      "2026-01-15 11:27:47,091 - logger - INFO - Epoch 40/150 | Train Loss: 0.6595 | Val Loss: 0.6091 | AUC: 0.1175 | LR: 6.25e-05 \n",
      "Train Epoch 40: 100%|██████████| 216/216 [00:06<00:00, 32.75it/s, loss=0.682, lr=6.25e-5]\n",
      "Val Epoch 40: 100%|██████████| 47/47 [00:00<00:00, 75.00it/s, loss=0.294]\n",
      "2026-01-15 11:27:54,986 - logger - INFO - Epoch 41/150 | Train Loss: 0.6700 | Val Loss: 0.6277 | AUC: 0.1161 | LR: 6.25e-05 \n",
      "Train Epoch 41: 100%|██████████| 216/216 [00:06<00:00, 32.11it/s, loss=0.863, lr=6.25e-5]\n",
      "Val Epoch 41: 100%|██████████| 47/47 [00:00<00:00, 79.93it/s, loss=0.306]\n",
      "2026-01-15 11:28:03,048 - logger - INFO - Epoch 42/150 | Train Loss: 0.6639 | Val Loss: 0.6258 | AUC: 0.1173 | LR: 6.25e-05 \n",
      "Train Epoch 42: 100%|██████████| 216/216 [00:06<00:00, 32.64it/s, loss=0.775, lr=6.25e-5]\n",
      "Val Epoch 42: 100%|██████████| 47/47 [00:00<00:00, 72.98it/s, loss=0.305]\n",
      "2026-01-15 11:28:11,010 - logger - INFO - Epoch 43/150 | Train Loss: 0.6629 | Val Loss: 0.6273 | AUC: 0.1153 | LR: 6.25e-05 \n",
      "Train Epoch 43: 100%|██████████| 216/216 [00:06<00:00, 32.47it/s, loss=0.83, lr=6.25e-5] \n",
      "Val Epoch 43: 100%|██████████| 47/47 [00:00<00:00, 81.82it/s, loss=0.308]\n",
      "2026-01-15 11:28:18,906 - logger - INFO - Epoch 44/150 | Train Loss: 0.6551 | Val Loss: 0.6303 | AUC: 0.1158 | LR: 6.25e-05 \n",
      "Train Epoch 44: 100%|██████████| 216/216 [00:06<00:00, 32.16it/s, loss=0.668, lr=6.25e-5]\n",
      "Val Epoch 44: 100%|██████████| 47/47 [00:00<00:00, 70.72it/s, loss=0.309]\n",
      "2026-01-15 11:28:26,963 - logger - INFO - Epoch 45/150 | Train Loss: 0.6595 | Val Loss: 0.6242 | AUC: 0.1161 | LR: 6.25e-05 \n",
      "2026-01-15 11:28:26,964 - logger - INFO - Early stop triggered after 45 epochs.\n",
      "2026-01-15 11:28:26,964 - logger - INFO - Traning Complete.\n",
      "Best Mean AUC: 0.1324\n",
      "2026-01-15 11:28:26,966 - logger - INFO - Loading checkpoint from c:\\Users\\Victo\\OneDrive\\Área de Trabalho\\Project-2\\project - 2\\runs\\20260115_112150\\checkpoints\\best_model.pth\n",
      "2026-01-15 11:28:27,029 - logger - INFO - Starting Testing Phase (using threshold: 0.7261)...\n",
      "Testing: 100%|██████████| 47/47 [00:00<00:00, 106.65it/s]\n",
      "2026-01-15 11:28:27,490 - logger - INFO - \n",
      "==================================================\n",
      "TEST RESULTS (Extreme Imbalance: 4.10% positive)\n",
      "==================================================\n",
      "  Loss:       0.5207\n",
      "  ROC AUC:    0.7495\n",
      "  PR AUC:     0.1364 (key metric for imbalanced data)\n",
      "==================================================\n",
      "At Val-Optimal Threshold (0.7261):\n",
      "  F1 Score:   0.1812\n",
      "  Precision:  0.1140\n",
      "  Recall:     0.4421\n",
      "  Specificity:0.8531\n",
      "  TP: 214, FP: 1664, FN: 270, TN: 9664\n",
      "==================================================\n",
      "Test-Optimal Threshold: 0.7408 (F1=0.1898)\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training finished.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    dm = DataModule(\n",
    "        data_path, \n",
    "        batch_size=config.model.batch_size, \n",
    "        num_workers=config.model.num_workers, \n",
    "        pin_memory=config.model.pin_memory, \n",
    "        logger=logger,\n",
    "        use_balanced_sampling=config.model.use_balanced_sampling,\n",
    "        oversample_ratio=config.model.oversample_ratio\n",
    "    )\n",
    "    dm.prepare_data()\n",
    "\n",
    "    model = Model(\n",
    "        embedding_dims=dm.emb_dims, \n",
    "        n_cont=len(dm.cont_cols), \n",
    "        outcome_dim=config.model.outcome_dim, \n",
    "        hidden_dim=config.model.hidden_dim, \n",
    "        n_blocks=config.model.n_blocks,     \n",
    "        dropout=config.model.dropout, \n",
    "        n_heads=config.model.n_heads,\n",
    "        use_grn=config.model.use_grn,\n",
    "        use_cross_attention=config.model.use_cross_attention\n",
    "    )\n",
    "    \n",
    "    logger.info(f\"Parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model, dm, \n",
    "        epochs=config.model.epochs, \n",
    "        lr=config.model.lr,\n",
    "        weight_decay=config.model.weight_decay, \n",
    "        logger=logger,\n",
    "        patience=config.model.patience, \n",
    "        mixed_precision=config.model.mixed_precision,\n",
    "        checkpoint_dir=checkpoint_dir, \n",
    "        max_grad_norm=config.model.max_grad_norm,\n",
    "        scheduler_factor=config.model.scheduler_factor,\n",
    "        scheduler_patience=config.model.scheduler_patience, \n",
    "        min_lr=config.model.min_lr,\n",
    "        loss_type=config.model.loss_type,\n",
    "        focal_alpha=config.model.focal_alpha,\n",
    "        focal_gamma=config.model.focal_gamma\n",
    "    )\n",
    "    \n",
    "    best_model = trainer.fit()\n",
    "    trainer.test(dm.test_dataloader())\n",
    "    torch.save(best_model.state_dict(), model_save_path)\n",
    "    print(\"Training finished.\")\n",
    "\n",
    "except Exception as e:\n",
    "    logger.error(f\"Failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "finally:\n",
    "    logger.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepGPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
